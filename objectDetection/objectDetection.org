#+TITLE: Object Detection .py
#+AUTHOR: Vishakh Kumar





#+BEGIN_SRC python :tangle objectDetection.py
import time 
import requests
import cv2
import operator
import numpy as np
from __future__ import print_function

###############################################################################
# Variables                                                                   #
_url = 'https://westcentralus.api.cognitive.microsoft.com/vision/v1/analyses' #
_key = 'XXXXXXXXXXXXXXXXXXXXXXXXXXXXX'                                        #
_maxNumRetries = 10                                                           #
###############################################################################



# We should have image in memory already if we're using this.
# Load raw image file into memory
#pathToFileInDisk = r'D:\tmp\3.jpg'
#with open( pathToFileInDisk, 'rb' ) as f:
#    data = f.read()


#+END_SRC


* Identifying useful categories
So Micrsoft has a bunch of items it can identify and I'd like to throw away any items I don't care about. So I have the microsoft category list and I have the list of stuff I care about.
The variable categoty_List is the final list of categories I care about.

Why'd I do it this way? Because I'm guessing that the categories I care about are likely to change with time.

#+BEGIN_SRC txt

#+END_SRC



#+BEGIN_SRC python :tangle objectDetection.py
# All of Microsoft's categories
microsoftCategories = [
"abstract_",
"abstract_net",
"abstract_nonphoto",
"abstract_rect",
"abstract_shape",
"abstract_texture",
"animal_",
"animal_bird",
"animal_cat",
"animal_dog",
"animal_horse",
"animal_panda",
"building_",
"building_arch",
"building_brickwall",
"building_church",
"building_corner",
"building_doorwindows",
"building_pillar",
"building_stair",
"building_street",
"dark_",
"drink_",
"drink_can",
"dark_fire",
"dark_fireworks",
"sky_object",
"food_",
"food_bread",
"food_fastfood",
"food_grilled",
"food_pizza",
"indoor_",
"indoor_churchwindow",
"indoor_court",
"indoor_doorwindows",
"indoor_marketstore",
"indoor_room",
"indoor_venue",
"dark_light",
"others_",
"outdoor_",
"outdoor_city",
"outdoor_field",
"outdoor_grass",
"outdoor_house",
"outdoor_mountain",
"outdoor_oceanbeach",
"outdoor_playground",
"outdoor_railway",
"outdoor_road",
"outdoor_sportsfield",
"outdoor_stonerock",
"outdoor_street",
"outdoor_water",
"outdoor_waterside",
"people_",
"people_baby",
"people_crowd",
"people_group",
"people_hand",
"people_many",
"people_portrait",
"people_show",
"people_tattoo",
"people_young",
"plant_",
"plant_branch",
"plant_flower",
"plant_leaves",
"plant_tree",
"object_screen",
"object_sculpture",
"sky_cloud",
"sky_sun",
"people_swimming",
"outdoor_pool",
"text_",
"text_mag",
"text_map",
"text_menu",
"text_sign",
"trans_bicycle",
"trans_bus",
"trans_car",
"trans_trainstation"]


#Categories I care about
myCategories=[
"food",
"trans",
"drink",
"object",
"animal",
"plant"
]

# Finds matches in the microsoft list for each item in my list and then flattens the list and then removes duplicates by changing into a set and then back into a list.
category_List = list(set(      sum(  [[s for s in microsoftCategories if x in s] for x in myCategories]   ,     [])            )) 
#+END_SRC

* Identify Image
#+BEGIN_SRC python :tangle objectDetection.py
def identifyImage(image):
    
# Computer Vision parameters
params = { 'visualFeatures' : 'Color,Categories'} 
headers = dict()
headers['Ocp-Apim-Subscription-Key'] = _key
headers['Content-Type'] = 'application/octet-stream'

json = None
result = processRequest( json, image, headers, params )

if result is not None:
# Holy shit, you actually have a result. What do I do!
  return image
else:
  return None
#+END_SRC
** Process Request

Magic shit that I don't care about. I've built stuff around this so don't pay too much attention. Just read the comments.
#+BEGIN_SRC python :tangle objectDetection.py
# The magic happens here, I guess
def processRequest( json, data, headers, params ):
    """
    Helper function to process the request to Project Oxford
    Parameters:
    json: Used when processing images from its URL. See API Documentation
    data: Used when processing image read from disk. See API Documentation
    headers: Used to pass the key information and the data type request
    """

    retries = 0
    result = None
    while True:
        # The actual request happens over here and the response is saved.
        response = requests.request( 'post', _url, json = json, data = data, headers = headers, params = params )

# You've sent too many requests in too short a period of time.
        if response.status_code == 429: 
            print( "Message: %s" % ( response.json()['error']['message'] ) )
            if retries <= _maxNumRetries: 
                time.sleep(1) 
                retries += 1
                continue
            else: 
                print( 'Error: failed after retrying!' )
                break

# If your response is a success, do this
        elif response.status_code == 200 or response.status_code == 201:

            if 'content-length' in response.headers and int(response.headers['content-length']) == 0: 
                # The API didn't recognize anything. This should not happen.
                result = None 


            elif 'content-type' in response.headers and isinstance(response.headers['content-type'], str): 
                # The api actually recognized something!

                if 'application/json' in response.headers['content-type'].lower(): 
                    result = response.json() if response.content else None 

                elif 'image' in response.headers['content-type'].lower(): 
                    result = response.content
        else:
# If your response is a failure for whatever reason, do this.
            print( "Error code: %d" % ( response.status_code ) )
            print( "Message: %s" % ( response.json()['error']['message'] ) )
        break
    return result







#+END_SRC

* Identify Category

This is there so that I can trash objects rather quickly if they make no sense whatsoever. I expect that the user will just have to take a photo again.
#+BEGIN_SRC python
def checkIfValidCategory(result):
  if result.categories[0].name in myCategories:
    return True
  else:
    return False
#+END_SRC 

* Identify Most Useful Tag

This is to trash as many useless tags as I can






* Google Stuff

#+BEGIN_SRC python
import os
import cv2
import time
import argparse
import multiprocessing
import numpy as np
import tensorflow as tf
from matplotlib import pyplot as plt
# matplotlib inline

from object_detection.utils import label_map_util
from object_detection.utils import visualization_utils as vis_util

CWD_PATH = os.getcwd()

# Path to frozen detection graph. This is the actual model that is used for the object detection.
MODEL_NAME = 'ssd_mobilenet_v1_coco_11_06_2017'
PATH_TO_CKPT = os.path.join(CWD_PATH, 'object_detection', MODEL_NAME, 'frozen_inference_graph.pb')

# List of the strings that is used to add correct label for each box.
PATH_TO_LABELS = os.path.join(CWD_PATH, 'object_detection', 'data', 'mscoco_label_map.pbtxt')

NUM_CLASSES = 90

# Loading label map
label_map = label_map_util.load_labelmap(PATH_TO_LABELS)
categories = label_map_util.convert_label_map_to_categories(label_map, max_num_classes=NUM_CLASSES,
                                                            use_display_name=True)
category_index = label_map_util.create_category_index(categories)


def detect_objects(image_np, sess, detection_graph):
    # Expand dimensions since the model expects images to have shape: [1, None, None, 3]
    image_np_expanded = np.expand_dims(image_np, axis=0)
    image_tensor = detection_graph.get_tensor_by_name('image_tensor:0')

    # Each box represents a part of the image where a particular object was detected.
    boxes = detection_graph.get_tensor_by_name('detection_boxes:0')

    # Each score represent how level of confidence for each of the objects.
    # Score is shown on the result image, together with the class label.
    scores = detection_graph.get_tensor_by_name('detection_scores:0')
    classes = detection_graph.get_tensor_by_name('detection_classes:0')
    num_detections = detection_graph.get_tensor_by_name('num_detections:0')

    # Actual detection.
    (boxes, scores, classes, num_detections) = sess.run(
        [boxes, scores, classes, num_detections],
        feed_dict={image_tensor: image_np_expanded})

    # Visualization of the results of a detection.
    vis_util.visualize_boxes_and_labels_on_image_array(
        image_np,
        np.squeeze(boxes),
        np.squeeze(classes).astype(np.int32),
        np.squeeze(scores),
        category_index,
        use_normalized_coordinates=True,
        line_thickness=8)
    return image_np


# First test on images
PATH_TO_TEST_IMAGES_DIR = 'object_detection/test_images'
TEST_IMAGE_PATHS = [ os.path.join(PATH_TO_TEST_IMAGES_DIR, 'image{}.jpg'.format(i)) for i in range(1, 3) ]

# Size, in inches, of the output images.
IMAGE_SIZE = (12, 8)


def load_image_into_numpy_array(image):
  (im_width, im_height) = image.size
  return np.array(image.getdata()).reshape(
      (im_height, im_width, 3)).astype(np.uint8)

from PIL import Image
for image_path in TEST_IMAGE_PATHS:
    image = Image.open(image_path)
    image_np = load_image_into_numpy_array(image)
    plt.imshow(image_np)
    print(image.size, image_np.shape)


#Load a frozen TF model 
detection_graph = tf.Graph()
with detection_graph.as_default():
    od_graph_def = tf.GraphDef()
    with tf.gfile.GFile(PATH_TO_CKPT, 'rb') as fid:
        serialized_graph = fid.read()
        od_graph_def.ParseFromString(serialized_graph)
        tf.import_graph_def(od_graph_def, name='')



with detection_graph.as_default():
    with tf.Session(graph=detection_graph) as sess:
        for image_path in TEST_IMAGE_PATHS:
            image = Image.open(image_path)
            image_np = load_image_into_numpy_array(image)
            image_process = detect_objects(image_np, sess, detection_graph)
            print(image_process.shape)
            plt.figure(figsize=IMAGE_SIZE)
            plt.imshow(image_process)




#+END_SRC







